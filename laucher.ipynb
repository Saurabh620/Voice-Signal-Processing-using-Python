{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c052e2-d169-48b7-a615-7ca672c0561b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C97818F920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 364ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk  \n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "import sounddevice as sd\n",
    "import soundfile as sf \n",
    "import time\n",
    "# Load the model\n",
    "model = load_model('model/SER_model.h5') \n",
    "emojis = {\n",
    "    'Angry': 'üò°',\n",
    "    'Disgust': 'ü§¢',\n",
    "    'Fear': 'üò®',\n",
    "    'Happy': 'üòä',\n",
    "    'Neutral': 'üòê',\n",
    "    'Pleasant Surprise': 'üòÆ',\n",
    "    'Sad': 'üòî'\n",
    "}\n",
    "USE_PIE_CHART = True\n",
    "\n",
    "def show_prediction(predicted_emotion, predicted_emoji):\n",
    "    loading_label.pack_forget()  \n",
    "    predicted_emotion_text.set(f\"Predicted Emotion: {predicted_emotion} {predicted_emoji}\")\n",
    "    loading_bar.stop() \n",
    "    \n",
    "    \n",
    "def extract_mfcc(filename):\n",
    "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    return mfcc, y, sr\n",
    "\n",
    "def predict_emotion(audio_file):\n",
    "    mfcc, _, _ = extract_mfcc(audio_file)\n",
    "    mfcc = mfcc.reshape(1, 40, 1)\n",
    "    predictions = model.predict(mfcc)\n",
    "    return predictions[0]  # Return the probabilities for all emotions\n",
    "\n",
    "    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Pleasant Surprise', 'Sad']\n",
    "    return emotions[predicted_label]\n",
    "\n",
    "def plot_waveform(filename, sr, y):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Create a figure and axis\n",
    "    ax.set_title('Audio Waveform')\n",
    "    ax.plot(np.linspace(0, len(y) / sr, num=len(y)), y)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.grid()\n",
    "    return fig  # Return the figure\n",
    "\n",
    "\n",
    "def record_and_process():\n",
    "    def process_recorded_audio():\n",
    "        file_path = \"recorded_audio.wav\"  # Get the recorded audio file path\n",
    "        process_audio(file_path)  # Process the recorded audio for prediction\n",
    "\n",
    "    try:\n",
    "        global loading_label, loading_bar\n",
    "\n",
    "        loading_label = tk.Label(root, text=\"Recording Audio...\", font=(\"Arial\", 14))\n",
    "        loading_label.pack(pady=20)\n",
    "        root.update()  # Update the GUI to show the label\n",
    "\n",
    "        loading_bar = ttk.Progressbar(root, orient='horizontal', length=200, mode='indeterminate')\n",
    "        loading_bar.pack(pady=10)\n",
    "\n",
    "        def stop_recording():\n",
    "            loading_label.config(text=\"Recording stopped\")\n",
    "            loading_bar.stop()\n",
    "\n",
    "        # Record audio\n",
    "        duration = 3  # Set the duration of recording in seconds\n",
    "        fs = 44100  # Set the sampling frequency\n",
    "\n",
    "        audio_data = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "\n",
    "        file_path = \"recorded_audio.wav\"  # Define the file path to save the recorded audio\n",
    "        sf.write(file_path, audio_data, fs)  # Save the recorded audio to a file\n",
    "        loading_label.config(text=\"Recording finished\")\n",
    "        loading_bar.stop()\n",
    "\n",
    "        root.after(1000, process_recorded_audio)  # Schedule processing of recorded audio after 1 second\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_loading():\n",
    "    loading_label.pack_forget()\n",
    "\n",
    "\n",
    "def open_file():\n",
    "    def process_recorded_audio():\n",
    "        file_path = \"recorded_audio.wav\"  # Get the recorded audio file path\n",
    "        process_audio(file_path)  # Process the recorded audio for prediction\n",
    "\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "    if file_path:\n",
    "        try:\n",
    "            global loading_label\n",
    "            loading_label = tk.Label(root, text=\"Predicting Emotion...\", font=(\"Arial\", 14))\n",
    "            loading_label.pack(pady=20)\n",
    "\n",
    "            global loading_bar\n",
    "            loading_bar = ttk.Progressbar(root, orient='horizontal', length=200, mode='indeterminate')\n",
    "            loading_bar.pack(pady=10)\n",
    "            loading_bar.start()\n",
    "\n",
    "            # Check if a file is selected or audio needs to be recorded\n",
    "            if file_path == \"\":\n",
    "                # Record audio if no file is selected\n",
    "                file_path = record_audio()\n",
    "                # Schedule processing of recorded audio after 3 seconds\n",
    "                root.after(3000, process_recorded_audio)\n",
    "            else:\n",
    "                # Process the selected audio file\n",
    "                root.after(5000, lambda: process_audio(file_path))\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "def process_audio(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        predicted_probabilities = predict_emotion(file_path)\n",
    "        emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Pleasant Surprise', 'Sad']\n",
    "\n",
    "        fig, (ax_waveform, ax_probs) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "        # Plot waveform\n",
    "        ax_waveform.set_title('Audio Waveform')\n",
    "        ax_waveform.plot(np.linspace(0, len(y) / sr, num=len(y)), y)\n",
    "        ax_waveform.set_xlabel('Time (s)')\n",
    "        ax_waveform.set_ylabel('Amplitude')\n",
    "        ax_waveform.grid()\n",
    "\n",
    "        # Plot emotion probabilities as a bar chart\n",
    "        ax_probs.bar(emotions, predicted_probabilities, color='skyblue')\n",
    "        ax_probs.set_xlabel('Emotions')\n",
    "        ax_probs.set_ylabel('Probability')\n",
    "        ax_probs.set_title('Emotion Probabilities')\n",
    "        ax_probs.tick_params(axis='x', labelrotation=45)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "        # Show predicted emotion text on top of the window\n",
    "        predicted_emotion = emotions[np.argmax(predicted_probabilities)]\n",
    "        predicted_emoji = emojis.get(predicted_emotion, 'Unknown Emoji')\n",
    "        predicted_emotion_text.set(f\"Predicted Emotion: {predicted_emotion} {predicted_emoji}\")\n",
    "\n",
    "        fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "\n",
    "        # Pack the figure into a tkinter window\n",
    "        canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "        canvas.get_tk_widget().pack(padx=10, pady=10)\n",
    "        canvas.draw()\n",
    "\n",
    "        show_prediction(predicted_emotion, predicted_emoji)\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def create_gui():\n",
    "    global root\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Emotion Predictor\")\n",
    "    root.geometry(\"800x600\")  # Set a fixed size for the window\n",
    "\n",
    " \n",
    "    signal_processing_heading = tk.Label(root, text=\"Signal Processing\", font=(\"Arial\", 18))\n",
    "    signal_processing_heading.pack()\n",
    "\n",
    "    # Create a frame for the file selection and predicted text\n",
    "    file_frame = tk.Frame(root)\n",
    "    file_frame.pack(pady=20)\n",
    "\n",
    "    # Add the predicted emotion text with larger font size\n",
    "    global predicted_emotion_text\n",
    "    predicted_emotion_text = tk.StringVar()\n",
    "    predicted_emotion_label = tk.Label(file_frame, textvariable=predicted_emotion_text, font=(\"Arial\", 31))\n",
    "    predicted_emotion_label.pack()\n",
    "\n",
    "    button = tk.Button(file_frame, text=\"Select Audio File\", command=open_file)\n",
    "    button.pack(padx=20, pady=10)\n",
    "    \n",
    "    button = tk.Button(file_frame, text=\"Record Audio\", command=record_and_process)\n",
    "    button.pack(padx=20, pady=10)\n",
    "\n",
    "    # Create a frame for the plot and emojis\n",
    "    plot_frame = tk.Frame(root)\n",
    "    plot_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f1979-caba-45e5-bc76-491f0325cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37883e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ae434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
